{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NICE2019: BrainScaleS-2 Tutorial 2019-03-29\n",
    "\n",
    "\n",
    "<img src=\"img/hicann_neurons_cutout.png\" style=\"width:100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main contributors:\n",
    "* Phillip Spilger <img src=\"img/psp.jpg\" style=\"width:20%\" />\n",
    "* Timo Wunderlich <img src=\"img/timow.jpg\" style=\"width:20%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common features of the BrainScaleS architectures:\n",
    "\n",
    "* **Analog** implementation\n",
    "* **Physical model**: Neurons and synapses realized on CMOS\n",
    "* **Time-continuous**/non-multiplexed\n",
    "* Spikes events are digital & asynchronous\n",
    "* Configurable (model parameters, connectivity/topology)\n",
    "* **Accelerated** model (10³ - 10⁴ times faster compared to biological model time constants)\n",
    "\n",
    "\n",
    "\n",
    "## HICANN-DLS v2 Prototype\n",
    "\n",
    "For this tutorial we will use a small prototype containing 32 neurons (LIF), and 1024 synapses in total.\n",
    "The acceleration factor is approx. 1000 compared to the biological model.\n",
    "An embedded SIMD processor extends the possiblilites compares to BrainScaleS-1 and other analog systems.\n",
    "\n",
    "<img src=\"img/IMG_0038.JPG\" style=\"width:30%\" />\n",
    "\n",
    "* Targeting flexible plasticity rules and on-the-fly continuous reconfiguration (modifications of STDP learning rule, structural plasticity)\n",
    "* Offload software tasks to embedded (plasticity) processor (PPU):\n",
    "  * Supervised learning\n",
    "  * External rewards\n",
    "  * Reinforcement learning\n",
    "  * Neuronal plasticity (calibration)\n",
    "  * Anything you can code…\n",
    "  * At any time scale (bio-ms to bio-years)\n",
    "  * Scalability and standalone operation\n",
    "\n",
    "\n",
    "## Latest BrainScaleS-2 chip: HICANN-X\n",
    "\n",
    "(Cf. Johannes talk)\n",
    "\n",
    "<img src=\"img/HICANNX_small.jpg\" style=\"width:30%\" />\n",
    "\n",
    "* Structured neurons\n",
    "* \"ANN\"-mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded processor dedicated to programmable plasticity?\n",
    "\n",
    "### Observables:\n",
    "\n",
    "* Per-synapse pre-post correlation measurements <img src=\"img/friedmann_correlation.png\" width=\"50%\" />\n",
    "* Neuron spike counts\n",
    "* Spike events (in/out)\n",
    "\n",
    "### Controllables:\n",
    "\n",
    "* Weights (& connectivity)\n",
    "* Neuron parameters & structure, . . .\n",
    "\n",
    "### Allows for\n",
    "\n",
    "* (Two-factor) and reward-modulated STDP\n",
    "* Structural plasticity\n",
    "* Homeostasis\n",
    "* Other, phenomenological plasticity rules\n",
    "\n",
    "### What else?\n",
    "\n",
    "* Interaction with virtual environments <img src=\"img/paper_timo_expoverview.png\" width=\"50%\" />\n",
    "* Motor/sensor loops\n",
    "* *“Model debugging”, e.g. snapshotting some state variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrator Videos\n",
    "\n",
    "* Local Learning Demo on BrainScaleS-2 https://youtu.be/LW0Y5SSIQU4\n",
    "* Unsupervised learning Demo on BrainScaleS-2 https://youtu.be/x3l1xl8orhQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Overview\n",
    "\n",
    "This notebook serves as a hands-on tutorial to the HICANN-DLS v2 prototype chip. Later full-sized chips, such as HICANN-X, are in many aspects very similar to this prototype.\n",
    "\n",
    "The following schematic shows the software layers. This tutorial covers the `haldls` and `stadls` layers.\n",
    "\n",
    "<img src=\"img/bss2_software_stack_modified.png\" width=\"30%\" />\n",
    "\n",
    "We will learn:\n",
    "* how to create an initial configuration (neuron & synapse parameters, technical settings)\n",
    "* how to design an experiment *protocol* (→ timed sequence of input spikes)\n",
    "* how to upload and run the configuration and experiment protocol\n",
    "* how to download the result data and plot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0: Single neuron stimulation\n",
    "\n",
    "* generating stimulation data\n",
    "* configure single neuron\n",
    "* stimulate with spike train\n",
    "* read back spike data\n",
    "* plot input and output spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulation / Spike Train\n",
    "The following function simply returns a \"Poisson spike train\":\n",
    "\n",
    "```python\n",
    "import numpy\n",
    "def generate_poisson_spiketrain(isi, time_interval):\n",
    "    dts = numpy.random.exponential(isi, size=time_interval / isi)\n",
    "    spikes = numpy.add.accumulate(dts, dtype=int)\n",
    "    return spikes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BrainScaleS systems use a mixture of circuit switching and tag/label filtering to address synapses. In order to send a spike train to a certain synapse we have to add \"target synapse driver\" (→ target row in the synapse array) and \"label\" information (synapses have a configurable filter on labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from dlens.v2 import hal # PlaybackSpike\n",
    "\n",
    "def generate_poisson_spiketrain(isi, timeframe, label, synapse_driver):\n",
    "    dts = numpy.random.exponential(isi, size=timeframe / isi)\n",
    "    ts = numpy.add.accumulate(dts, dtype=int)\n",
    "    spikes = []\n",
    "    for t in ts:\n",
    "        spikes.append(hal.PlaybackSpike(t, label, synapse_driver))\n",
    "    return spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate spike trains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlens.v2 import halco # SynapseDriverOnDLS\n",
    "\n",
    "# inter-spike interval\n",
    "noise_isi = 1000\n",
    "\n",
    "# time interval of spikes (implicitly start from t=0)\n",
    "timeframe = 100000\n",
    "\n",
    "# target synapse driver (row)\n",
    "target_synapse_driver = halco.SynapseDriverOnDLS(23)\n",
    "\n",
    "# target synapse label\n",
    "target_synapse_label1 = 42\n",
    "target_synapse_label2 = 43\n",
    "\n",
    "spike_train1 = generate_poisson_spiketrain(noise_isi, timeframe,\n",
    "                                          target_synapse_label1, target_synapse_driver)\n",
    "spike_train2 = generate_poisson_spiketrain(noise_isi, timeframe,\n",
    "                                          target_synapse_label2, target_synapse_driver)\n",
    "\n",
    "spike_train1.sort()\n",
    "spike_train2.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy, math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.eventplot([spike.time for spike in spike_train1], color=['red'],\n",
    "              lineoffsets=[target_synapse_label1], label=\"Spike Train 1\")\n",
    "plt.eventplot([spike.time for spike in spike_train2], color=['blue'],\n",
    "              lineoffsets=[target_synapse_label2], label=\"Spike Train 2\")\n",
    "\n",
    "plt.yticks(range(int(math.ceil(min(plt.yticks()[0]))), int(math.ceil(max(plt.yticks()[0])))))\n",
    "plt.title(\"DLSv2 single neuron spike measurement\")\n",
    "plt.xlabel(\"Spike Time [hardware cycles, 10ns]\")\n",
    "plt.ylabel(\"Spike Identifier\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the individual hardware system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign an DLS Setup to each jupyter user (based on userid)\n",
    "import os\n",
    "userid = int(os.environ['HOME'].split('/')[-1])\n",
    "print(\"My user id: {}\".format(userid))\n",
    "DLSSetups = ['B291656', 'B201330'] #, '07', 'B291698'] # available systems\n",
    "DLSSetup = DLSSetups[userid % len(DLSSetups)]\n",
    "print(\"This notebook will use Setup {}\".format(DLSSetup))\n",
    "os.environ['USER']='s1ext_user1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 0 Experiment: Configure hardware, provide input data, run emulation and read back data\n",
    "\n",
    "We hide the default setup code in tutorial_configuration.py (if interested: open via Jupyter's File dialog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stage0.py\n",
    "\n",
    "from dlens import logger\n",
    "from dlens.v2 import hal, sta, halco\n",
    "from dlens.v2.halco import NeuronOnDLS, NeuronParameter, SynapseOnDLS\n",
    "\n",
    "from tutorial_configuration import TutorialBoard, TutorialChip\n",
    "\n",
    "import os\n",
    "BOARD_ID = os.environ[\"QUIGGELDY_BOARD\"]\n",
    "\n",
    "logger.default_config(level=logger.LogLevel.INFO)\n",
    "\n",
    "import numpy\n",
    "\n",
    "def generate_poisson_spiketrain(isi, timeframe, address, synapse_driver):\n",
    "    dts = numpy.random.exponential(isi, size=timeframe / isi)\n",
    "    ts = numpy.add.accumulate(dts, dtype=int)\n",
    "    spikes = []\n",
    "    for t in ts:\n",
    "        spikes.append(hal.PlaybackSpike(t, address, synapse_driver))\n",
    "    return spikes\n",
    "\n",
    "class SingleNeuronSpikes:\n",
    "    def __init__(self):\n",
    "        self.ctrl = sta.ExperimentControl()\n",
    "        self.board = TutorialBoard()\n",
    "        self.chip = TutorialChip()\n",
    "\n",
    "    def execute(self, leak, nrn, noise_isi = 1000, timeframe = 1000000, excitatory_weight = 63):\n",
    "        \"\"\"\n",
    "        This script emplaces excitatory Poisson noise onto a neuron via one synapse and\n",
    "        measures the neuron spikes.\n",
    "\n",
    "        :param leak: Leak potential to set prior to sending the spiketrain\n",
    "        :type leak: hal.DAC.Value\n",
    "        :param nrn: Neuron to stimulate\n",
    "        :type nrn: NeuronOnDLS coordinate\n",
    "        :param noise_isi: Mean inter-spike-interval of Poisson spike sources\n",
    "        :type noise_isi: int\n",
    "        :param timeframe: Timeframe of spiketrains\n",
    "        :type timeframe: int\n",
    "        :param excitatory_weight: Weight of synaptic connection to excitatory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :return: Spikes sent and spikes received\n",
    "        :rtype: list[list[hal.PlaybackSpike], list[hal.RecordedSpike]]\n",
    "        \"\"\"\n",
    "\n",
    "        # Logger object\n",
    "        log = logger.get(\"execute\")\n",
    "\n",
    "        # Set leak potential\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            self.chip.capmem.set(nrn, NeuronParameter.v_leak, leak)\n",
    "\n",
    "        synapse_address = hal.SynapseBlock.Synapse.Address(42) # arbitrary != 0\n",
    "\n",
    "        # Configure excitatory background synapses\n",
    "        synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                 self.chip.get_excitatory_synapse_driver().toSynapseRowOnDLS())\n",
    "        synapse = self.chip.get_synapse(synapse_coord)\n",
    "        synapse.weight = excitatory_weight\n",
    "        synapse.address = synapse_address\n",
    "        self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Create a playback program (all times are in FPGA cycles / 96MHz)\n",
    "        builder = hal.PlaybackProgramBuilder()\n",
    "\n",
    "        # Create excitatory and Poisson spiketrain\n",
    "        input_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_excitatory_synapse_driver())\n",
    "        input_spikes.sort()\n",
    "\n",
    "        # Add spikes to playback program\n",
    "        builder.set_time(0)\n",
    "        for spike in input_spikes:\n",
    "            builder.wait_until(spike.time)\n",
    "            builder.fire(spike.synapse_driver, spike.source_address)\n",
    "        builder.halt()\n",
    "        program = builder.done()\n",
    "        assert isinstance(program, hal.PlaybackProgram)\n",
    "\n",
    "        self.ctrl.run_experiment(self.board, self.chip, program)\n",
    "\n",
    "        neuron_spikes = program.get_spikes()\n",
    "        log.TRACE(\"Received spikes: %s\" % neuron_spikes)\n",
    "\n",
    "        return [input_spikes, neuron_spikes]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment = SingleNeuronSpikes()\n",
    "\n",
    "    neuron = NeuronOnDLS(1)\n",
    "    #neuron = NeuronOnDLS(17)\n",
    "    #neuron = NeuronOnDLS(4)\n",
    "    input_spikes, neuron_spikes = experiment.execute(leak=400, noise_isi=200, nrn=neuron, timeframe=20000)\n",
    "\n",
    "    input_spike_times = [spike.time for spike in input_spikes]\n",
    "    neuron_spike_times = [spike.time for spike in neuron_spikes]\n",
    "    \n",
    "    #print len(neuron_spike_times)\n",
    "    #print len(input_spike_times)\n",
    "    \n",
    "    numpy.save('neuron_spike_times.data', numpy.array(neuron_spike_times))\n",
    "    numpy.save('input_spike_times.data', numpy.array(input_spike_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the experiment into the queuing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -p dls --daas={DLSSetup} -- singularity exec --app visionary-dls /containers/stable/latest python stage0.py\n",
    "!ls *spike_times.data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy, math\n",
    "\n",
    "neuron_spike_times = numpy.load('neuron_spike_times.data.npy')\n",
    "input_spike_times = numpy.load('input_spike_times.data.npy')\n",
    "\n",
    "plt.eventplot([input_spike_times], color=['blue'], lineoffsets=[1], label=\"Input spikes\")\n",
    "plt.eventplot([neuron_spike_times], color=['red'], lineoffsets=[0], label=\"Neuron output spikes\")\n",
    "plt.yticks(range(int(math.ceil(min(plt.yticks()[0]))), int(math.ceil(max(plt.yticks()[0])))))\n",
    "plt.title(\"DLSv2 single neuron spike measurement\")\n",
    "plt.xlabel(\"Spike Time [hardware cycles, 10ns]\")\n",
    "plt.ylabel(\"Spike Identifier\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0b: Decreasing weights over time\n",
    "\n",
    "We can use the embedded processor to change model parameters during experiment runtime.\n",
    "\n",
    "* Decrease weights periodically (with weight-wrap-around) until experiment end time is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile spike_counter_loop_decrease_weight_over_time.cc\n",
    "\n",
    "#include <stddef.h>\n",
    "#include <stdint.h>\n",
    "extern \"C\"\n",
    "{\n",
    "#include \"libnux/counter.h\"\n",
    "#include \"libnux/dls.h\"\n",
    "#include \"libnux/spr.h\"\n",
    "#include \"libnux/syn.h\"\n",
    "#include \"libnux/time.h\"\n",
    "}\n",
    "\n",
    "extern uint8_t ram_end;\n",
    "\n",
    "// This program reads out neuron-local spike counters in a loop. The per-neuron accumulation is\n",
    "// stored to a defined memory address range after reading for a defined timeframe for readout from\n",
    "// the host.\n",
    "\n",
    "// Program entry point\n",
    "extern \"C\" int start()\n",
    "{\n",
    "\tvector uint8_t excitatory_weights_l;\n",
    "\tvector uint8_t excitatory_weights_r;\n",
    "\n",
    "\tuint8_t excitatory_row = 0;\n",
    "\n",
    "\t// Timeframe of spike count measurement\n",
    "\ttime_base_t constexpr timeframe = 2000000;\n",
    "\n",
    "\t// Sleep period [cycles] between consecutive readouts\n",
    "\tuint32_t constexpr sleep_period = 10000;\n",
    "    \n",
    "    // read in initial weights\n",
    "\tget_weights(&excitatory_weights_l, &excitatory_weights_r, excitatory_row);\n",
    "\n",
    "\t// decrease weights over time (w/ wrap around)\n",
    "\twhile (get_time_base() < timeframe) {\n",
    "\n",
    "\t\texcitatory_weights_l = excitatory_weights_l - vec_splat_u8(1);\n",
    "\t\texcitatory_weights_r = excitatory_weights_r - vec_splat_u8(1);\n",
    "\n",
    "\t\tset_weights(&excitatory_weights_l, &excitatory_weights_r, excitatory_row);\n",
    "\n",
    "\t\tsleep_cycles(sleep_period);\n",
    "\t}\n",
    "\n",
    "\treturn 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-compiling of code for embedded processor\n",
    "\n",
    "We use a build tool for compilation of host code as well as PPU code. For demonstration, we perform the individual steps explicitly in this tutorial.\n",
    "\n",
    "The first step: Compile the source into an object file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!powerpc-ppu-g++ -std=gnu++14 -fdiagnostics-color=always -O2 -fno-strict-aliasing -Wall -Wextra -pedantic -ffreestanding -mcpu=nux -std=gnu++11 -fno-exceptions -fno-rtti -fno-non-call-exceptions -fno-common -ffunction-sections -fdata-sections -Ilibnux -Ilibnux -Idemo-dls/src/ppu -Idemo-dls/src/ppu -DLIBNUX_DLS_VERSION=2 -DNDEBUG -DSYSTEM_HICANN_DLS_MINI spike_counter_loop_decrease_weight_over_time.cc -c -ospike_counter_loop_decrease_weight_over_time.cc.7.o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second step: Link the object file and helper libraries (there is no full runtime available on the PPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!powerpc-ppu-g++ -fuse-ld=bfd -nostdlib -Lbuild/libnux -Tlibnux/libnux/elf32nux.x -Wl,--gc-sections spike_counter_loop_decrease_weight_over_time.cc.7.o build/libnux/libnux/counter.c.10.o build/libnux/libnux/time.c.9.o build/libnux/src/crt.s.6.o build/libnux/src/cxa_pure_virtual.c.4.o build/libnux/src/initdeinit.c.3.o -ofirmware/spike_counter_loop_decrease_weight_over_time.bin -Bstatic -Llibnux -lgcc -lnux -Bdynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step: Strip down the output file to the binary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!powerpc-ppu-objcopy -O binary firmware/spike_counter_loop_decrease_weight_over_time.bin firmware/spike_counter_loop_decrease_weight_over_time.binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment description (part not running on the embedded processor)\n",
    "\n",
    "The host experiment script is very similar to the previous one. The main difference is the specification of a executable for the embedded processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stage0b.py\n",
    "\n",
    "from dlens import logger\n",
    "from dlens.v2 import hal, sta, halco\n",
    "from dlens.v2.halco import NeuronOnDLS, NeuronParameter, SynapseOnDLS\n",
    "\n",
    "from tutorial_configuration import TutorialBoard, TutorialChip\n",
    "\n",
    "logger.default_config(level=logger.LogLevel.INFO)\n",
    "\n",
    "import numpy\n",
    "\n",
    "def generate_poisson_spiketrain(isi, timeframe, address, synapse_driver):\n",
    "    dts = numpy.random.exponential(isi, size=timeframe / isi)\n",
    "    ts = numpy.add.accumulate(dts, dtype=int)\n",
    "    spikes = []\n",
    "    for t in ts:\n",
    "        spikes.append(hal.PlaybackSpike(t, address, synapse_driver))\n",
    "    return spikes\n",
    "\n",
    "class SingleNeuronSpikes:\n",
    "    def __init__(self):\n",
    "        self.ctrl = sta.ExperimentControl()\n",
    "        self.board = TutorialBoard()\n",
    "        self.chip = TutorialChip()\n",
    "\n",
    "    def execute(self, leak, nrn, noise_isi = 1000, timeframe = 1000000,\n",
    "                excitatory_weight = 63):\n",
    "        \"\"\"\n",
    "        This script emplaces excitatory Poisson noise onto a neuron via one synapse and\n",
    "        measures the neuron spikes.\n",
    "\n",
    "        :param leak: Leak potential to set prior to sending the spiketrain\n",
    "        :type leak: hal.DAC.Value\n",
    "        :param nrn: Neuron to stimulate\n",
    "        :type nrn: NeuronOnDLS coordinate\n",
    "        :param noise_isi: Mean inter-spike-interval of Poisson spike sources\n",
    "        :type noise_isi: int\n",
    "        :param timeframe: Timeframe of spiketrains\n",
    "        :type timeframe: int\n",
    "        :param excitatory_weight: Weight of synaptic connection to excitatory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :return: Spikes sent and spikes received\n",
    "        :rtype: list[list[hal.PlaybackSpike], list[hal.RecordedSpike]]\n",
    "        \"\"\"\n",
    "\n",
    "        # Logger object\n",
    "        log = logger.get(\"execute\")\n",
    "\n",
    "        # Set leak potential\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            self.chip.capmem.set(nrn, NeuronParameter.v_leak, leak)\n",
    "\n",
    "        synapse_address = hal.SynapseBlock.Synapse.Address(42) # arbitrary != 0\n",
    "\n",
    "        # Configure excitatory background synapses\n",
    "        synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                 self.chip.get_excitatory_synapse_driver().toSynapseRowOnDLS())\n",
    "        synapse = self.chip.get_synapse(synapse_coord)\n",
    "        synapse.weight = excitatory_weight\n",
    "        synapse.address = synapse_address\n",
    "        self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Create a playback program (all times are in FPGA cycles / 96MHz)\n",
    "        builder = hal.PlaybackProgramBuilder()\n",
    "\n",
    "        # Create excitatory and Poisson spiketrain\n",
    "        input_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_excitatory_synapse_driver())\n",
    "        input_spikes.sort()\n",
    "\n",
    "        # Create PPU (Plasticity Processing Unit) memory object and load pragram\n",
    "        ppu_memory = hal.PPUMemory()\n",
    "        ppu_memory.load_from_file(\"firmware/spike_counter_loop_decrease_weight_over_time.binary\")\n",
    "\n",
    "        # Pull PPU-reset\n",
    "        ppu_control_register = hal.PPUControlRegister()\n",
    "        ppu_control_register.inhibit_reset = False\n",
    "        builder.write(halco.PPUControlRegisterOnDLS(), ppu_control_register)\n",
    "\n",
    "        # Write PPU memory\n",
    "        builder.write(halco.PPUMemoryOnDLS(), ppu_memory)\n",
    "\n",
    "        # Release PPU-reset\n",
    "        ppu_control_register.inhibit_reset = True\n",
    "        builder.write(halco.PPUControlRegisterOnDLS(), ppu_control_register)\n",
    "\n",
    "        # Add spikes to playback program\n",
    "        builder.set_time(0)\n",
    "        for spike in input_spikes:\n",
    "            builder.wait_until(spike.time)\n",
    "            builder.fire(spike.synapse_driver, spike.source_address)\n",
    "        builder.halt()\n",
    "        program = builder.done()\n",
    "        assert isinstance(program, hal.PlaybackProgram)\n",
    "\n",
    "        self.ctrl.run_experiment(self.board, self.chip, program)\n",
    "\n",
    "        neuron_spikes = program.get_spikes()\n",
    "        log.TRACE(\"Received spikes: %s\" % neuron_spikes)\n",
    "\n",
    "        return [input_spikes, neuron_spikes]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment = SingleNeuronSpikes()\n",
    "\n",
    "    neuron = NeuronOnDLS(1)\n",
    "    #neuron = NeuronOnDLS(17)\n",
    "    #neuron = NeuronOnDLS(4)\n",
    "    input_spikes, neuron_spikes = \\\n",
    "        experiment.execute(leak=400, noise_isi=500, nrn=neuron, timeframe=2000000)\n",
    "\n",
    "    input_spike_times = [spike.time for spike in input_spikes]\n",
    "    neuron_spike_times = [spike.time for spike in neuron_spikes]\n",
    "    \n",
    "    #print len(neuron_spike_times)\n",
    "    #print len(input_spike_times)\n",
    "    \n",
    "    numpy.save('neuron_spike_times.data', numpy.array(neuron_spike_times))\n",
    "    numpy.save('input_spike_times.data', numpy.array(input_spike_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the experiment into the queuing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!srun -p dls --daas={DLSSetup} -- singularity exec --app visionary-dls /containers/stable/latest python stage0b.py\n",
    "!ls *spike_times.data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy, math\n",
    "\n",
    "neuron_spike_times = numpy.load('neuron_spike_times.data.npy')\n",
    "input_spike_times = numpy.load('input_spike_times.data.npy')\n",
    "\n",
    "plt.eventplot([input_spike_times], color=['blue'], lineoffsets=[1], label=\"Input spikes\")\n",
    "plt.eventplot([neuron_spike_times], color=['red'], lineoffsets=[0], label=\"Neuron output spikes\")\n",
    "plt.yticks(range(int(math.ceil(min(plt.yticks()[0]))), int(math.ceil(max(plt.yticks()[0])))))\n",
    "plt.title(\"DLSv2 single neuron spike measurement\")\n",
    "plt.xlabel(\"Spike Time [hardware cycles, 10ns]\")\n",
    "plt.ylabel(\"Spike Identifier\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stage 1: Recording neuronal activation functions\n",
    "\n",
    "* Neurons receive balanced Poisson noise.\n",
    "* Measure \"spiking probability\" as function of resting membrane potential.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1: Use Host to read spikes from FPGA.\n",
    "\n",
    "* Spikes from the chip are buffered in the FPGA.\n",
    "* Read spikes from FPGA and count them at different resting potentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `NeuronActivation` encapsulates the board & chip configuration and is used to run the experiment and collect output spikes.\n",
    "All times are given in units of FPGA cycles (T = 10.2 nanoseconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stage1_host_file1.py\n",
    "\n",
    "import numpy\n",
    "from tutorial_configuration import TutorialBoard, TutorialChip\n",
    "\n",
    "from dlens import logger\n",
    "from dlens.v2 import hal, sta, halco\n",
    "from dlens.v2.halco import NeuronOnDLS, NeuronParameter, SynapseOnDLS\n",
    "\n",
    "#logger.default_config(level=logger.LogLevel.INFO)\n",
    "logger.default_config(level=logger.LogLevel.ERROR)\n",
    "\n",
    "def generate_poisson_spiketrain(isi, timeframe, address, synapse_driver):\n",
    "    dts = numpy.random.exponential(isi, size=timeframe / isi)\n",
    "    ts = numpy.add.accumulate(dts, dtype=int)\n",
    "    spikes = []\n",
    "    for t in ts:\n",
    "        spikes.append(hal.PlaybackSpike(t, address, synapse_driver))\n",
    "    return spikes\n",
    "\n",
    "class NeuronActivation:\n",
    "    def __init__(self):\n",
    "        self.ctrl = sta.ExperimentControl()\n",
    "        self.board = TutorialBoard()\n",
    "        self.chip = TutorialChip()\n",
    "\n",
    "    def execute(self, leak, noise_isi = 1000, timeframe = 1000000, excitatory_weight = 50, inhibitory_weight = 50):\n",
    "        \"\"\"\n",
    "        This script measures the neuron activation of all neurons in parallel by sending excitatory and\n",
    "        inhibitory Poisson spiketrains and measuring the number of neuron spikes per neuron.\n",
    "\n",
    "        :param leak: Leak potential to set prior to sending the spiketrains\n",
    "        :type leak: hal.DAC.Value\n",
    "        :param noise_isi: Mean inter-spike-interval of Poisson spike sources\n",
    "        :type noise_isi: int\n",
    "        :param timeframe: Timeframe of spiketrains\n",
    "        :type timeframe: int\n",
    "        :param excitatory_weight: Weight of synaptic connection to excitatory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :param inhibitory_weight: Weight of synaptic connection to inhibitory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :return: Spikes received\n",
    "        :rtype: list[hal.RecordedSpike]\n",
    "        \"\"\"\n",
    "\n",
    "        # Set leak potential\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            self.chip.capmem.set(nrn, NeuronParameter.v_leak, leak)\n",
    "\n",
    "        synapse_address = hal.SynapseBlock.Synapse.Address(42) # arbitrary != 0\n",
    "\n",
    "        # Configure excitatory background synapses\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                     self.chip.get_excitatory_synapse_driver().toSynapseRowOnDLS())\n",
    "            synapse = self.chip.get_synapse(synapse_coord)\n",
    "            synapse.weight = excitatory_weight\n",
    "            synapse.address = synapse_address\n",
    "            self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Configure inhibitory background synapses\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                     self.chip.get_inhibitory_synapse_driver().toSynapseRowOnDLS())\n",
    "            synapse = self.chip.get_synapse(synapse_coord)\n",
    "            synapse.weight = inhibitory_weight\n",
    "            synapse.address = synapse_address\n",
    "            self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Create a playback program (all times are in FPGA cycles / 96MHz)\n",
    "        builder = hal.PlaybackProgramBuilder()\n",
    "\n",
    "        # Create excitatory and inhibitory poisson spiketrains\n",
    "        excitatory_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_excitatory_synapse_driver())\n",
    "        inhibitory_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_inhibitory_synapse_driver())\n",
    "        all_spikes = excitatory_spikes + inhibitory_spikes\n",
    "        all_spikes.sort()\n",
    "\n",
    "        # Add spikes to playback program\n",
    "        builder.set_time(0)\n",
    "        for spike in all_spikes:\n",
    "            builder.wait_until(spike.time)\n",
    "            builder.fire(spike.synapse_driver, spike.source_address)\n",
    "        builder.halt()\n",
    "        program = builder.done()\n",
    "        assert isinstance(program, hal.PlaybackProgram)\n",
    "\n",
    "        self.ctrl.run_experiment(self.board, self.chip, program)\n",
    "\n",
    "        spikes = program.get_spikes()\n",
    "        return spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code section uses `NeuronActivation`  to sweep the neurons' `leak` parameter.\n",
    "The  membrane leak potential DAC value (12-bit digital value) is typically set in the range (300, 700).\n",
    "We can use `NeuronActivation.execute(leak=X, ...)` to perform an experiment with a given `leak` and retrieve the output of the experiment (spikes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stage1_host_file2.py\n",
    "\n",
    "neuron_activation = NeuronActivation()\n",
    "\n",
    "nrn_spike_counts = []\n",
    "\n",
    "#dac_value = 300\n",
    "#spikes = neuron_activation.execute(leak=dac_value, timeframe=2000000)\n",
    "#nrn_spike_counts.append([dac_value, len(spikes)])\n",
    "\n",
    "# Execute activation measurement for a leak potential sweep\n",
    "for dac_value in range(300, 701, 10):\n",
    "    spikes = neuron_activation.execute(leak=dac_value, timeframe=2000000)\n",
    "    nrn_spike_count = [0 for nrn in halco.iter_all(NeuronOnDLS)]\n",
    "    for spike in spikes:\n",
    "        nrn_spike_count[int(spike.neuron)] += 1\n",
    "    nrn_spike_counts.append([dac_value, nrn_spike_count])\n",
    "\n",
    "# most certainly this can be made more beautiful\n",
    "zipped = zip(*nrn_spike_counts)\n",
    "#print zipped[0]\n",
    "#print zipped[1]\n",
    "transposed = numpy.transpose(zipped[1])\n",
    "\n",
    "numpy.save('host_vleak_values.data', numpy.array(zipped[0]))\n",
    "numpy.save('host_activity_values.data', numpy.array(transposed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardware setup is shared between multiple users, we use SLURM as a resource manager and submit the experiment into a \"job queue\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat stage1_host_file*.py > stage1_host.py\n",
    "!srun -p dls --daas={DLSSetup} -- singularity exec --app visionary-dls /containers/stable/latest python stage1_host.py\n",
    "!ls host_*values.data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experiment completion, we read inb the result data files and generate a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "host_vleak_values = numpy.load('host_vleak_values.data.npy')\n",
    "host_activity_values = numpy.load('host_activity_values.data.npy')\n",
    "\n",
    "for i in range(len(host_activity_values)):\n",
    "    plt.plot(host_vleak_values, 1.0 * host_activity_values[i] / host_activity_values[i][-1],\n",
    "             '.-', label='Neuron {}'.format(i))\n",
    "\n",
    "plt.title(\"DLSv2 neuron activation measurement (Host)\")\n",
    "plt.ylim([-0.15, 1.15])\n",
    "plt.xlabel(\"Leak potential [lsb]\")\n",
    "plt.ylabel(\"Activity normalized\")\n",
    "plt.legend(ncol=2, fontsize='xx-small')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Use on-chip processor to measure neuron spike rates\n",
    "\n",
    "* Each neuron has a spike counter which can be read (and reset) by the embedded processor.\n",
    "* The read-out has to happen before any counter saturates (255 spikes!).\n",
    "* On the embedded processor: Run the read-out in a loop, accumulate into per-neuron variables.\n",
    "* Transfer data to the host.\n",
    "* Repeat processor for different neuron resting potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile stage1_ppu.py\n",
    "\n",
    "from dlens import logger\n",
    "from dlens.v2 import hal, sta, halco\n",
    "from dlens.v2.halco import NeuronOnDLS, NeuronParameter, SynapseOnDLS\n",
    "\n",
    "from tutorial_configuration import TutorialBoard, TutorialChip\n",
    "logger.default_config(level=logger.LogLevel.INFO)\n",
    "\n",
    "import numpy\n",
    "\n",
    "def generate_poisson_spiketrain(isi, timeframe, address, synapse_driver):\n",
    "    dts = numpy.random.exponential(isi, size=timeframe / isi)\n",
    "    ts = numpy.add.accumulate(dts, dtype=int)\n",
    "    spikes = []\n",
    "    for t in ts:\n",
    "        spikes.append(hal.PlaybackSpike(t, address, synapse_driver))\n",
    "    return spikes\n",
    "\n",
    "class NeuronActivation:\n",
    "    def __init__(self):\n",
    "        self.ctrl = sta.ExperimentControl()\n",
    "        self.board = TutorialBoard()\n",
    "        self.chip = TutorialChip()\n",
    "\n",
    "    def execute(self, leak, noise_isi = 1000, timeframe = 10000000, excitatory_weight = 63, inhibitory_weight = 63):\n",
    "        \"\"\"\n",
    "        This script measures the neuron activation of all neurons in parallel by sending excitatory and\n",
    "        inhibitory Poisson spiketrains and measuring the number of neuron spikes per neuron.\n",
    "\n",
    "        :param leak: Leak potential to set prior to sending the spiketrains\n",
    "        :type leak: hal.DAC.Value\n",
    "        :param noise_isi: Mean inter-spike-interval of Poisson spike sources\n",
    "        :type noise_isi: int\n",
    "        :param timeframe: Timeframe of spiketrains\n",
    "        :type timeframe: int\n",
    "        :param excitatory_weight: Weight of synaptic connection to excitatory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :param inhibitory_weight: Weight of synaptic connection to inhibitory spiketrain\n",
    "        :type timeframe: hal.SynapseBlock.Synapse.Weight\n",
    "        :return: Spikes received\n",
    "        :rtype: list[hal.RecordedSpike]\n",
    "        \"\"\"\n",
    "\n",
    "        # Logger object\n",
    "        log = logger.get(\"execute\")\n",
    "\n",
    "        # Set leak potential\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            self.chip.capmem.set(nrn, NeuronParameter.v_leak, leak)\n",
    "\n",
    "        synapse_address = hal.SynapseBlock.Synapse.Address(42) # arbitrary != 0\n",
    "\n",
    "        # Configure excitatory background synapses\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                     self.chip.get_excitatory_synapse_driver().toSynapseRowOnDLS())\n",
    "            synapse = self.chip.get_synapse(synapse_coord)\n",
    "            synapse.weight = excitatory_weight\n",
    "            synapse.address = synapse_address\n",
    "            self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Configure inhibitory background synapses\n",
    "        for nrn in halco.iter_all(NeuronOnDLS):\n",
    "            synapse_coord = SynapseOnDLS(nrn.toSynapseColumnOnDLS(),\n",
    "                                     self.chip.get_inhibitory_synapse_driver().toSynapseRowOnDLS())\n",
    "            synapse = self.chip.get_synapse(synapse_coord)\n",
    "            synapse.weight = inhibitory_weight\n",
    "            synapse.address = synapse_address\n",
    "            self.chip.set_synapse(synapse_coord, synapse)\n",
    "\n",
    "        # Create a playback program (all times are in FPGA cycles / 96MHz)\n",
    "        builder = hal.PlaybackProgramBuilder()\n",
    "\n",
    "        # Create excitatory and inhibitory poisson spiketrains\n",
    "        excitatory_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_excitatory_synapse_driver())\n",
    "        inhibitory_spikes = generate_poisson_spiketrain(noise_isi, timeframe, synapse_address, \\\n",
    "            self.chip.get_inhibitory_synapse_driver())\n",
    "        all_spikes = excitatory_spikes + inhibitory_spikes\n",
    "        all_spikes.sort()\n",
    "\n",
    "        # Create PPU (Plasticity Processing Unit) memory object and load pragram\n",
    "        ppu_memory = hal.PPUMemory()\n",
    "        ppu_memory.load_from_file(\"firmware/spike_counter_loop.binary\")\n",
    "\n",
    "        # Pull PPU-reset\n",
    "        ppu_control_register = hal.PPUControlRegister()\n",
    "        ppu_control_register.inhibit_reset = False\n",
    "        builder.write(halco.PPUControlRegisterOnDLS(), ppu_control_register)\n",
    "\n",
    "        # Write PPU memory\n",
    "        builder.write(halco.PPUMemoryOnDLS(), ppu_memory)\n",
    "\n",
    "        # Release PPU-reset\n",
    "        ppu_control_register.inhibit_reset = True\n",
    "        builder.write(halco.PPUControlRegisterOnDLS(), ppu_control_register)\n",
    "\n",
    "        # Add spikes to playback program\n",
    "        builder.set_time(0)\n",
    "        for spike in all_spikes:\n",
    "            builder.wait_until(spike.time)\n",
    "            builder.fire(spike.synapse_driver, spike.source_address)\n",
    "        \n",
    "        # wait some additional time at the end\n",
    "        builder.wait_for(10000)\n",
    "        \n",
    "        # Read PPU status\n",
    "        ppu_status_ticket = builder.read(halco.PPUStatusRegisterOnDLS())\n",
    "\n",
    "        # Read end-of-PPU-RAM range, where the PPU stored spike count information\n",
    "        ppu_spike_count_coordinate = halco.PPUMemoryBlockOnDLS(4096 - NeuronOnDLS.size, 4095)\n",
    "        ppu_spike_count_ticket = builder.read(ppu_spike_count_coordinate)\n",
    "\n",
    "        builder.halt()\n",
    "        program = builder.done()\n",
    "        assert isinstance(program, hal.PlaybackProgram)\n",
    "\n",
    "        self.ctrl.run_experiment(self.board, self.chip, program)\n",
    "\n",
    "        ppu_status = ppu_status_ticket.get()\n",
    "        # PPU finished execution\n",
    "        assert (ppu_status.sleep == True)\n",
    "\n",
    "        ppu_spike_count = ppu_spike_count_ticket.get()\n",
    "        log.DEBUG([int(word.get()) for word in ppu_spike_count.words])\n",
    "\n",
    "        spikes = program.get_spikes()\n",
    "        log.TRACE(\"Received spikes: %s\" % spikes)\n",
    "\n",
    "        return [int(word.get()) for word in ppu_spike_count.words]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    neuron_activation = NeuronActivation()\n",
    "\n",
    "    # Execute activation measurement for a leak potential sweep\n",
    "    nrn_spike_counts = []\n",
    "    for leak in range(300, 701, 10):\n",
    "        nrn_spike_count = neuron_activation.execute(leak)\n",
    "        nrn_spike_counts.append([leak, nrn_spike_count])\n",
    "\n",
    "    # most certainly this can be made more beautiful\n",
    "    zipped = zip(*nrn_spike_counts)\n",
    "    print zipped[0]\n",
    "    print zipped[1]\n",
    "    transposed = numpy.transpose(zipped[1])\n",
    "    \n",
    "    numpy.save('ppu_vleak_values.data', numpy.array(zipped[0]))\n",
    "    numpy.save('ppu_activity_values.data', numpy.array(transposed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C++ code for the embedded processor can be found in `spike_counter_loop.cc` (open via File dialog if interested).\n",
    "\n",
    "The program reads out neuron-local spike counters in a loop. The per-neuron accumulation is stored to a defined memory address range after reading for a defined timeframe for readout from the host:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "// Pointer to end of heap memory\n",
    "extern uint8_t ram_end;\n",
    "\n",
    "// Spike count accumulator storage\n",
    "uint32_t spike_counts[dls_num_columns]; // dls_num_columns ==  number of neurons\n",
    "\n",
    "for (uint32_t& count: spike_counts) {\n",
    "    count = 0;\n",
    "}\n",
    "\n",
    "// Timeframe of spike count measurement\n",
    "time_base_t constexpr timeframe = 10000000;\n",
    "\n",
    "// Sleep period [cycles] between consecutive readouts\n",
    "uint32_t constexpr sleep_period = 10000;\n",
    "\n",
    "// Reset counters to only measure spikes emitted during the loop below\n",
    "reset_all_neuron_counters();\n",
    "\n",
    "// Read spike count and accumulate\n",
    "while (get_time_base() < timeframe) {\n",
    "    for (size_t nrn = 0; nrn < dls_num_columns; ++nrn) {\n",
    "        uint32_t count = get_neuron_counter(nrn);\n",
    "        spike_counts[nrn] += count;\n",
    "    }\n",
    "    sleep_cycles(sleep_period);\n",
    "}\n",
    "\n",
    "// Write results to end of RAM\n",
    "uint32_t* pos = reinterpret_cast<uint32_t*>(&ram_end) - dls_num_columns;\n",
    "for (size_t i = 0; i < dls_num_columns; ++i) {\n",
    "    *pos = spike_counts[i];\n",
    "    pos++;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!powerpc-ppu-g++ -std=gnu++14 -fdiagnostics-color=always -O2 -fno-strict-aliasing -Wall -Wextra -pedantic -ffreestanding -mcpu=nux -std=gnu++11 -fno-exceptions -fno-rtti -fno-non-call-exceptions -fno-common -ffunction-sections -fdata-sections -Ilibnux -Ilibnux -Idemo-dls/src/ppu -Idemo-dls/src/ppu -DLIBNUX_DLS_VERSION=2 -DNDEBUG -DSYSTEM_HICANN_DLS_MINI spike_counter_loop.cc -c -ospike_counter_loop.cc.7.o\n",
    "!powerpc-ppu-g++ -fuse-ld=bfd -nostdlib -Lbuild/libnux -Tlibnux/libnux/elf32nux.x -Wl,--gc-sections spike_counter_loop.cc.7.o build/libnux/libnux/counter.c.10.o build/libnux/libnux/time.c.9.o build/libnux/src/crt.s.6.o build/libnux/src/cxa_pure_virtual.c.4.o build/libnux/src/initdeinit.c.3.o -ofirmware/spike_counter_loop.bin -Bstatic -Llibnux -lgcc -lnux -Bdynamic\n",
    "!powerpc-ppu-objcopy -O binary firmware/spike_counter_loop.bin firmware/spike_counter_loop.binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!srun -p dls --daas={DLSSetup} -- singularity exec --app visionary-dls /containers/stable/latest python stage1_ppu.py\n",
    "!ls ppu*values.data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ppu_vleak_values = numpy.load('ppu_vleak_values.data.npy')\n",
    "ppu_activity_values = numpy.load('ppu_activity_values.data.npy')\n",
    "\n",
    "for i in range(len(ppu_activity_values)):\n",
    "    plt.plot(ppu_vleak_values, 1.0 * ppu_activity_values[i] / ppu_activity_values[i][-1],\n",
    "            '.-')\n",
    "\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.title(\"DLSv2 neuron activation (PPU)\")\n",
    "plt.xlabel(\"Leak potential [lsb]\")\n",
    "plt.ylabel(\"Activity normalized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 visionary-dls",
   "language": "python",
   "name": "visionary-dls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
